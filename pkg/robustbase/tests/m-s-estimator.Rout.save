
R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ## Test implementation of M-S estimator
> require(robustbase)
Loading required package: robustbase
> lmrob.conv.cc <- robustbase:::lmrob.conv.cc
> lmrob.psi2ipsi <- robustbase:::lmrob.psi2ipsi
> lmrob.wgtfun <- robustbase:::lmrob.wgtfun
> 
> ## dataset with factors and continuous variables:
> data(education)
> education <- within(education, Region <- factor(Region))
> ## for testing purposes:
> education2 <- within(education, Group <- factor(rep(1:3, length.out=length(Region))))
>                      
> ## Test lmrob.split
> testFun <- function(formula, x1.idx) {
+     obj <- lm(formula, education2)
+     mf <- obj$model
+     ret <- lmrob.split(mf)
+     if (missing(x1.idx)) {
+         print(ret$x1.idx)
+         return(which(unname(ret$x1.idx)))
+     }
+     stopifnot(all.equal(x1.idx, which(unname(ret$x1.idx))))
+ }
> testFun(Y ~ 1, integer(0))
> testFun(Y ~ X1*X2*X3, integer(0))
> testFun(Y ~ Region + X1 + X2 + X3, 1:4)
> testFun(Y ~ 0 + Region + X1 + X2 + X3, 1:4)
> testFun(Y ~ Region*X1 + X2 + X3, c(1:5, 8:10))
> testFun(Y ~ Region*X1 + X2 + X3 + Region*Group, c(1:5, 8:18))
> testFun(Y ~ Region*X1 + X2 + X3 + Region*Group*X2, c(1:6, 8:29))
> testFun(Y ~ Region*X1 + X2 + Region*Group*X2, 1:28)
> testFun(Y ~ Region*X1 + X2 + Region:Group:X2, 1:21)
> testFun(Y ~ Region*X1 + X2*X3 + Region:Group:X2, c(1:6, 8:10, 12:23))
> testFun(Y ~ (X1+X2+X3+Region)^2, c(1:7,10:12,14:19))
> testFun(Y ~ (X1+X2+X3+Region)^3, c(1:19, 21:29))
> testFun(Y ~ (X1+X2+X3+Region)^4, 1:32)
> 
> ## Test subsampling algorithm
> m_s_subsample <- function(x1, x2, y, control, orthogonalize=TRUE) {
+     x1 <- as.matrix(x1)
+     x2 <- as.matrix(x2)
+     y <- y
+     storage.mode(x1) <- "double"
+     storage.mode(x2) <- "double"
+     storage.mode(y) <- "double"
+     
+     z <- .C(robustbase:::R_lmrob_M_S,
+             X1=x1,
+             X2=x2,
+             y=y,
+             n=length(y),
+             p1=ncol(x1),
+             p2=ncol(x2),
+             nResample=as.integer(control$nResample),
+             scale=double(1),
+             b1=double(ncol(x1)),
+             b2=double(ncol(x2)),
+             tuning_chi=as.double(control$tuning.chi),
+             ipsi=as.integer(lmrob.psi2ipsi(control$psi)),
+             bb=as.double(control$bb),
+             K_m_s=as.integer(control$k.m_s),
+             max_k=as.integer(control$k.max),
+             rel_tol=as.double(control$rel.tol),
+             converged=logical(1),
+             trace_lev=as.integer(control$trace.lev),
+             orthogonalize=as.logical(orthogonalize),
+             subsample=TRUE,
+             descent=FALSE,
+             reweight=FALSE)
+     z[c("b1", "b2", "scale")]
+ }
> 
> control <- lmrob.control()
> obj <- lm(Y ~ Region + X1 + X2 + X3, education)
> splt <- lmrob.split(obj$model)
> y <- education$Y
> 
> ## test orthogonalizing
> x1 <- splt$x1
> x2 <- splt$x2
> tmp <- lmrob.lar(x1, y, control$rel.tol)
> y.tilde <- tmp$resid
> t1 <- tmp$coef
> x2.tilde <- x2
> T2 <- matrix(0, nrow=ncol(x1), ncol=ncol(x2))
> for (i in 1:ncol(x2)) {
+     tmp <- lmrob.lar(x1, x2[,i], control$rel.tol)
+     x2.tilde[,i] <- tmp$resid
+     T2[,i] <- tmp$coef
+ }
> set.seed(10)
> res1 <- m_s_subsample(x1, x2.tilde, y.tilde, control, FALSE)
> res1 <- within(res1, b1 <- drop(t1 + b1 - T2 %*% b2))
> set.seed(10)
> res2 <- m_s_subsample(x1, x2, y, control, TRUE)
> stopifnot(all.equal(res1, res2))
> 
> res <- list()
> set.seed(0)
> time <- system.time(for (i in 1:100) {
+     tmp <- m_s_subsample(x1, x2.tilde, y.tilde, control, FALSE)
+     res[[i]] <- unlist(within(tmp, b1 <- drop(t1 + b1 - T2 %*% b2)))
+ })
> cat('Time elapsed in subsampling: ', time,'\n')
Time elapsed in subsampling:  0.395 0 0.397 0 0 
> ## show a summary of the results
> res1 <- do.call(rbind, res)
> summary(res1)
      b11               b12              b13               b14       
 Min.   :-396.39   Min.   :-39.07   Min.   :-17.236   Min.   :16.22  
 1st Qu.:-224.09   1st Qu.:-23.38   1st Qu.: -8.241   1st Qu.:30.35  
 Median :-165.41   Median :-21.43   Median : -7.385   Median :32.55  
 Mean   :-166.64   Mean   :-21.52   Mean   : -7.404   Mean   :32.58  
 3rd Qu.:-102.66   3rd Qu.:-18.39   3rd Qu.: -6.478   3rd Qu.:35.95  
 Max.   : -33.62   Max.   :-12.23   Max.   :  1.154   Max.   :42.25  
      b21                b22               b23             scale      
 Min.   :-0.03808   Min.   :0.03168   Min.   :0.2953   Min.   :29.79  
 1st Qu.: 0.02009   1st Qu.:0.04004   1st Qu.:0.5024   1st Qu.:30.30  
 Median : 0.03095   Median :0.04672   Median :0.6382   Median :30.82  
 Mean   : 0.03050   Mean   :0.04594   Mean   :0.6346   Mean   :30.84  
 3rd Qu.: 0.04718   3rd Qu.:0.05110   3rd Qu.:0.8056   3rd Qu.:31.29  
 Max.   : 0.09728   Max.   :0.06792   Max.   :1.1109   Max.   :32.12  
> ## compare with fast S solution
> obj <- lmrob(Y ~ Region + X1 + X2 + X3, education, init="S")
> coef(obj)
  (Intercept)       Region2       Region3       Region4            X1 
-135.72600303  -20.64572279   -9.84882085   24.58011727    0.03405595 
           X2            X3 
   0.04327562    0.57895757 
> obj$scale
[1] 26.40388
> 
> ## Test descent algorithm
> m_s_descent <- function(x1, x2, y, control, b1, b2, scale) {
+     x1 <- as.matrix(x1)
+     x2 <- as.matrix(x2)
+     y <- y
+     storage.mode(x1) <- "double"
+     storage.mode(x2) <- "double"
+     storage.mode(y) <- "double"
+     
+     z <- .C(robustbase:::R_lmrob_M_S,
+             X1=x1,
+             X2=x2,
+             y=y,
+             n=length(y),
+             p1=ncol(x1),
+             p2=ncol(x2),
+             nResample=as.integer(control$nResample),
+             scale=as.double(scale),
+             b1=as.double(b1),
+             b2=as.double(b2),
+             tuning_chi=as.double(control$tuning.chi),
+             ipsi=as.integer(lmrob.psi2ipsi(control$psi)),
+             bb=as.double(control$bb),
+             K_m_s=as.integer(control$k.m_s),
+             max_k=as.integer(control$k.max),
+             rel_tol=as.double(control$rel.tol),
+             converged=logical(1),
+             trace_lev=as.integer(control$trace.lev),
+             orthogonalize=FALSE,
+             subsample=FALSE,
+             descent=TRUE,
+             reweight=FALSE)
+     z[c("b1", "b2", "scale")]
+ }
> 
> find_scale <- function(r, s0, n, p, control) {
+     c.chi <- lmrob.conv.cc(control$psi, control$tuning.chi)
+     
+     b <- .C(robustbase:::R_lmrob_S,
+             x = double(1),
+             y = as.double(r),
+             n = as.integer(n),
+             p = as.integer(p),
+             nResample = 0L,
+             scale = as.double(s0),
+             coefficients = double(p),
+             as.double(c.chi),
+             as.integer(lmrob.psi2ipsi(control$psi)),
+             as.double(control$bb),
+             best_r = 0L,
+             groups = 0L,
+             n.group = 0L,
+             k.fast.s = 0L,
+             k.iter = 0L,
+             refine.tol = as.double(control$refine.tol),
+             converged = logical(1),
+             trace.lev = 0L
+             )[c("coefficients", "scale", "k.iter", "converged")]
+     b$scale
+ }
> 
> ## what should it be:
> m_s_descent_Ronly<- function(x1, x2, y, control, b1, b2, scale) {
+     n <- length(y)
+     p1 <- ncol(x1)
+     p2 <- ncol(x2)
+     p <- p1+p2
+     t2 <- b2
+     t1 <- b1
+     rs <- drop(y - x1 %*% b1 - x2 %*% b2)
+     sc <- scale
+     ## do refinement steps
+     ## do maximally control$k.max iterations
+     ## stop if converged
+     ## stop after k.fast.m_s step of no improvement
+     if (control$trace.lev > 4) cat("scale:", scale, "\n")
+     if (control$trace.lev > 4) cat("res:", rs, "\n")
+     nnoimprovement <- nref <- 0; conv <- FALSE
+     while((nref <- nref + 1) <= control$k.max && !conv &&
+           nnoimprovement < control$k.m_s) {
+         ## STEP 1: UPDATE B2
+         y.tilde <- y - x1 %*% t1
+         w <- lmrob.wgtfun(rs / sc, control$tuning.chi, control$psi)
+         if (control$trace.lev > 4) cat("w:", w, "\n")
+         z2 <- lm.wfit(x2, y.tilde, w)
+         t2 <- z2$coef
+         if (control$trace.lev > 4) cat("t2:", t2, "\n")
+         rs <- y - x2 %*% t2
+         ## STEP 2: OBTAIN M-ESTIMATE OF B1
+         z1 <- lmrob.lar(x1, rs, control$rel.tol)
+         t1 <- z1$coef
+         if (control$trace.lev > 4) cat("t1:", t1, "\n")
+         rs <- z1$resid
+         ## STEP 3: COMPUTE THE SCALE ESTIMATE
+         sc <- find_scale(rs, sc, n, p, control)
+         if (control$trace.lev > 4) cat("sc:", sc, "\n")
+         ## STEP 4: CHECK FOR CONVERGENCE
+         #...
+         ## STEP 5: UPDATE BEST FIT
+         if (sc < scale) {
+             scale <- sc
+             b1 <- t1
+             b2 <- t2
+             nnoimprovement <- 0
+         } else nnoimprovement <- nnoimprovement + 1
+     }
+     ## STEP 6: FINISH
+     if (nref == control$k.max)
+         warning("M-S estimate: maximum number of refinement steps reached.")
+     
+     list(b1=b1, b2=b2, scale=scale)
+ }
> 
> control2 <- control
> #control2$trace.lev <- 5
> control2$k.max <- 1
> stopifnot(all.equal(m_s_descent(x1, x2, y, control2, res2$b1, res2$b2, res2$scale+10),
+                     m_s_descent_Ronly(x1, x2, y, control2, res2$b1, res2$b2, res2$scale+10),
+                     check.attr=FALSE))
> 
> ## control$k.m_s <- 100
> res2 <- list()
> time <- system.time(for (i in 1:100) {
+     res2[[i]] <- unlist(m_s_descent(x1, x2, y, control, res[[i]][1:4], res[[i]][5:7], res[[i]][8]))
+ })
> cat('Time elapsed in descent proc: ', time,'\n')
Time elapsed in descent proc:  0.079 0 0.079 0 0 
> 
> ## show a summary of the results
> res3 <- do.call(rbind, res2)
> summary(res3)
      b11               b12              b13               b14       
 Min.   :-396.39   Min.   :-39.07   Min.   :-16.100   Min.   :16.22  
 1st Qu.:-221.93   1st Qu.:-22.83   1st Qu.: -8.680   1st Qu.:27.92  
 Median :-161.54   Median :-21.28   Median : -7.837   Median :30.86  
 Mean   :-164.48   Mean   :-20.66   Mean   : -8.121   Mean   :31.00  
 3rd Qu.:-101.67   3rd Qu.:-18.09   3rd Qu.: -6.951   3rd Qu.:33.15  
 Max.   : -28.78   Max.   :-12.24   Max.   : -4.032   Max.   :42.25  
      b21                b22               b23             scale      
 Min.   :-0.02141   Min.   :0.03098   Min.   :0.3260   Min.   :29.79  
 1st Qu.: 0.02153   1st Qu.:0.03933   1st Qu.:0.5024   1st Qu.:30.30  
 Median : 0.04100   Median :0.04272   Median :0.6376   Median :30.48  
 Mean   : 0.04017   Mean   :0.04411   Mean   :0.6356   Mean   :30.70  
 3rd Qu.: 0.05842   3rd Qu.:0.04794   3rd Qu.:0.7799   3rd Qu.:30.96  
 Max.   : 0.08613   Max.   :0.06473   Max.   :1.1109   Max.   :32.11  
> 
> plot(res1[, "scale"], res3[,"scale"])
> 

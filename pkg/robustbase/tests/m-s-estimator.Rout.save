
R version 2.15.0 Patched (2012-05-23 r59426) -- "Easter Beagle"
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ## Test implementation of M-S estimator
> require(robustbase)
Loading required package: robustbase
> source(system.file("xtraR/m-s_fns.R", package = "robustbase", mustWork=TRUE))
> lmrob.conv.cc  <- robustbase::: lmrob.conv.cc
> lmrob.psi2ipsi <- robustbase::: lmrob.psi2ipsi
> lmrob.wgtfun   <- robustbase::: lmrob.wgtfun
> 
> ## dataset with factors and continuous variables:
> data(education)
> education <- within(education, Region <- factor(Region))
> ## for testing purposes:
> education2 <- within(education, Group <- factor(rep(1:3, length.out=length(Region))))
> 
> ## Test splitFrame (type fii is the only problematic type)
> testFun <- function(formula, x1.idx) {
+     obj <- lm(formula, education2)
+     mf <- obj$model
+     ret <- splitFrame(mf, type="fii")
+     if (missing(x1.idx)) {
+         print(ret$x1.idx)
+         return(which(unname(ret$x1.idx)))
+     }
+     stopifnot(identical(x1.idx, which(unname(ret$x1.idx))))
+ }
> testFun(Y ~ 1, integer(0))
> testFun(Y ~ X1*X2*X3, integer(0))
> testFun(Y ~ Region + X1 + X2 + X3, 1:4)
> testFun(Y ~ 0 + Region + X1 + X2 + X3, 1:4)
> testFun(Y ~ Region*X1 + X2 + X3, c(1:5, 8:10))
> testFun(Y ~ Region*X1 + X2 + X3 + Region*Group, c(1:5, 8:18))
> testFun(Y ~ Region*X1 + X2 + X3 + Region*Group*X2, c(1:6, 8:29))
> testFun(Y ~ Region*X1 + X2 + Region*Group*X2, 1:28)
> testFun(Y ~ Region*X1 + X2 + Region:Group:X2, 1:21)
> testFun(Y ~ Region*X1 + X2*X3 + Region:Group:X2, c(1:6, 8:10, 12:23))
> testFun(Y ~ (X1+X2+X3+Region)^2, c(1:7,10:12,14:19))
> testFun(Y ~ (X1+X2+X3+Region)^3, c(1:19, 21:29))
> testFun(Y ~ (X1+X2+X3+Region)^4, 1:32)
> testFun(Y ~ Region:X1:X2 + X1*X2, c(1:1, 4:7))
> 
> 
> control <- lmrob.control()
> f.lm <- lm(Y ~ Region + X1 + X2 + X3, education)
> splt <- splitFrame(f.lm$model)
> y <- education$Y
> 
> ## test orthogonalizing
> x1 <- splt$x1
> x2 <- splt$x2
> tmp <- lmrob.lar(x1, y, control)
> y.tilde <- tmp$resid
> t1 <- tmp$coef
> x2.tilde <- x2
> T2 <- matrix(0, nrow=ncol(x1), ncol=ncol(x2))
> for (i in 1:ncol(x2)) {
+     tmp <- lmrob.lar(x1, x2[,i], control)
+     x2.tilde[,i] <- tmp$resid
+     T2[,i] <- tmp$coef
+ }
> 
> set.seed(10)
> mss1 <- m_s_subsample(x1, x2.tilde, y.tilde, control, orth = FALSE)
> mss1 <- within(mss1, b1 <- drop(t1 + b1 - T2 %*% b2))
> set.seed(10)
> mss2 <- m_s_subsample(x1, x2,       y,       control, orth = TRUE)
> stopifnot(all.equal(mss1, mss2))
> 
> res <- vector("list", 100)
> set.seed(0)
> time <- system.time(for (i in seq_along(res)) {
+     tmp <- m_s_subsample(x1, x2.tilde, y.tilde, control, FALSE)
+     res[[i]] <- unlist(within(tmp, b1 <- drop(t1 + b1 - T2 %*% b2)))
+ })
> cat('Time elapsed in subsampling: ', time,'\n')
Time elapsed in subsampling:  0.456 0 0.458 0 0 
> ## show a summary of the results
> summary(res1 <- do.call(rbind, res))
      b11               b12              b13                b14       
 Min.   :-396.71   Min.   :-39.00   Min.   :-35.8704   Min.   :16.30  
 1st Qu.:-224.09   1st Qu.:-23.55   1st Qu.: -8.9603   1st Qu.:30.17  
 Median :-163.19   Median :-21.67   Median : -7.1441   Median :32.52  
 Mean   :-162.66   Mean   :-22.07   Mean   : -7.7680   Mean   :32.25  
 3rd Qu.:-103.36   3rd Qu.:-18.42   3rd Qu.: -5.6747   3rd Qu.:36.02  
 Max.   :  61.83   Max.   :-12.03   Max.   :  0.7015   Max.   :42.23  
      b21                b22               b23             scale      
 Min.   :-0.03808   Min.   :0.02111   Min.   :0.2555   Min.   :29.79  
 1st Qu.:-0.00158   1st Qu.:0.03960   1st Qu.:0.4956   1st Qu.:30.42  
 Median : 0.02179   Median :0.04716   Median :0.6381   Median :31.05  
 Mean   : 0.02686   Mean   :0.04620   Mean   :0.6271   Mean   :30.95  
 3rd Qu.: 0.05561   3rd Qu.:0.05211   3rd Qu.:0.7554   3rd Qu.:31.35  
 Max.   : 0.10074   Max.   :0.06765   Max.   :1.1121   Max.   :32.06  
> ## compare with fast S solution
> fmS <- lmrob(Y ~ Region + X1 + X2 + X3, education, init="S")
> coef(fmS)
  (Intercept)       Region2       Region3       Region4            X1 
-135.72592070  -20.64576533   -9.84881705   24.58013150    0.03405590 
           X2            X3 
   0.04327562    0.57895740 
> fmS$scale
[1] 26.40386
> 
> ###  Comparing m-s_descent implementations()  {our C and R} : ---------------------
> 
> ctrl <- control
> #ctrl$trace.lev <- 5
> ctrl$k.max <- 1
> mC <- m_s_descent      (x1, x2, y, ctrl, mss2$b1, mss2$b2, mss2$scale+10)
> mR <- m_s_descent_Ronly(x1, x2, y, ctrl, mss2$b1, mss2$b2, mss2$scale+10)
> nm <- c("b1","b2", "scale", "res")
> stopifnot(all.equal(mC[nm], mR[nm], check.attr = FALSE, tol=5e-15))
> 
> ## control$k.m_s <- 100
> res3 <- vector("list", 100)
> time <- system.time(for (i in seq_along(res3)) {
+     res3[[i]] <- unlist(m_s_descent(x1, x2, y, control,
+                                     res[[i]][1:4], res[[i]][5:7], res[[i]][8]))
+ })
> cat('Time elapsed in descent proc: ', time,'\n')
Time elapsed in descent proc:  0.108 0 0.107 0 0 
> 
> ## show a summary of the results
> res4 <- do.call(rbind, res3)
> summary(res4[,1:8])
      b11              b12              b13               b14       
 Min.   :-396.7   Min.   :-39.00   Min.   :-36.501   Min.   :16.30  
 1st Qu.:-223.9   1st Qu.:-23.02   1st Qu.: -8.956   1st Qu.:27.96  
 Median :-157.1   Median :-20.45   Median : -7.904   Median :30.31  
 Mean   :-158.6   Mean   :-20.29   Mean   : -8.896   Mean   :30.50  
 3rd Qu.:-102.3   3rd Qu.:-15.99   3rd Qu.: -6.858   3rd Qu.:32.59  
 Max.   : 101.7   Max.   :-12.24   Max.   : -4.032   Max.   :42.23  
      b21                b22               b23             scale      
 Min.   :-0.02122   Min.   :0.01459   Min.   :0.2034   Min.   :29.79  
 1st Qu.: 0.02142   1st Qu.:0.03838   1st Qu.:0.4956   1st Qu.:30.37  
 Median : 0.04687   Median :0.04154   Median :0.6293   Median :30.57  
 Mean   : 0.04289   Mean   :0.04320   Mean   :0.6263   Mean   :30.72  
 3rd Qu.: 0.06124   3rd Qu.:0.04764   3rd Qu.:0.7395   3rd Qu.:31.05  
 Max.   : 0.09102   Max.   :0.06476   Max.   :1.1121   Max.   :32.01  
> 
> plot(res1[, "scale"], res4[,"scale"])
> abline(0,1, col=adjustcolor("gray", 0.5))
> 
> ## Test lmrob.M.S
> x <- model.matrix(fmS)
> control$trace.lev <- 3
> set.seed(1003)
> fMS <- lmrob.M.S(x, y, control, fmS$model)
starting with subsampling procedure...
Step 0: new candidate with sc = 43.22688
Step 1: new candidate with sc = 33.12505
Step 18: new candidate with sc = 31.85586
Step 136: new candidate with sc = 31.74081
Step 338: new candidate with sc = 31.51188
Finished M-S subsampling with scale = 31.51188
b1: -5.445072 7.825257 1.756708 7.656800 
b2: 0.048442 0.037633 0.591759 
starting with descent procedure...
Refinement step 1: better fit, scale: 31.48594
Refinement step 4: better fit, scale: 31.38752
Refinement step 5: better fit, scale: 31.34287
Refinement step 6: better fit, scale: 31.32908
descent procedure: not converged.
b1: -113.528805 -14.858187 -9.426368 27.485299 
b2: 0.066846 0.036134 0.540701 
> resid <- drop(y - x %*% fMS$coef)
> stopifnot(all.equal(resid, fMS$resid, check.attr=FALSE))
> 
> ## Test direct call to lmrob
> set.seed(13)
> fiMS <- lmrob(Y ~ Region + X1 + X2 + X3, education, init="M-S")
> out2 <- capture.output(summary(fiMS))
> writeLines(out2)

Call:
lmrob(formula = Y ~ Region + X1 + X2 + X3, data = education, 
    init = "M-S")

Weighted Residuals:
    Min      1Q  Median      3Q     Max 
-61.780 -15.565  -1.574  23.457 174.698 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)   
(Intercept) -148.76973  142.58750  -1.043   0.3026   
Region2      -13.51425   16.60314  -0.814   0.4202   
Region3      -10.55037   15.86600  -0.665   0.5096   
Region4       22.21989   16.89960   1.315   0.1955   
X1             0.04079    0.05016   0.813   0.4206   
X2             0.04337    0.01368   3.170   0.0028 **
X3             0.60797    0.35014   1.736   0.0897 . 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Robust residual standard error: 30.2 
Convergence in 21 IRWLS iterations

Robustness weights: 
 observation 50 is an outlier with |weight| = 0 ( < 0.002); 
 7 weights are ~= 1. The remaining 42 ones are summarized as
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.2591  0.8877  0.9483  0.8848  0.9865  0.9983 
Algorithmic parameters: 
tuning.chi         bb tuning.psi    rel.tol 
 1.5476400  0.5000000  4.6850610  0.0000001 
 nResample     max.it      k.max      k.m_s  trace.lev        mts compute.rd 
       500         50        200         20          0       1000          0 
          psi   subsampling        method           cov    split.type 
   "bisquare" "constrained"        "M-SM"     ".vcov.w"           "f" 
seed : int(0) 
> 
> set.seed(13)
> fiM.S <- lmrob(Y ~ Region + X1 + X2 + X3, education, init=lmrob.M.S)
> out3 <- capture.output(summary(fiM.S))
> 
> ## must be the same {apart from the "init=" in the call}:
> stopifnot(identical(out2[-4], out3[-4]))
> 
> proc.time()
   user  system elapsed 
  1.100   0.016   1.110 

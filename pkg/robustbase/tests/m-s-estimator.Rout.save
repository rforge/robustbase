
R version 2.14.1 (2011-12-22)
Copyright (C) 2011 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ## Test implementation of M-S estimator
> require(robustbase)
Loading required package: robustbase
> lmrob.conv.cc <- robustbase:::lmrob.conv.cc
> lmrob.psi2ipsi <- robustbase:::lmrob.psi2ipsi
> 
> ## dataset with factors and continuous variables:
> data(education)
> education <- within(education, Region <- factor(Region))
> ## for testing purposes:
> education2 <- within(education, Group <- factor(rep(1:3, length.out=length(Region))))
>                      
> ## Test lmrob.split
> testFun <- function(formula, x1.idx) {
+     obj <- lm(formula, education2)
+     mf <- obj$model
+     ret <- lmrob.split(mf)
+     if (missing(x1.idx)) {
+         print(ret$x1.idx)
+         return(which(unname(ret$x1.idx)))
+     }
+     stopifnot(all.equal(x1.idx, which(unname(ret$x1.idx))))
+ }
> testFun(Y ~ 1, integer(0))
> testFun(Y ~ X1*X2*X3, integer(0))
> testFun(Y ~ Region + X1 + X2 + X3, 1:4)
> testFun(Y ~ 0 + Region + X1 + X2 + X3, 1:4)
> testFun(Y ~ Region*X1 + X2 + X3, c(1:5, 8:10))
> testFun(Y ~ Region*X1 + X2 + X3 + Region*Group, c(1:5, 8:18))
> testFun(Y ~ Region*X1 + X2 + X3 + Region*Group*X2, c(1:6, 8:29))
> testFun(Y ~ Region*X1 + X2 + Region*Group*X2, 1:28)
> testFun(Y ~ Region*X1 + X2 + Region:Group:X2, 1:21)
> testFun(Y ~ Region*X1 + X2*X3 + Region:Group:X2, c(1:6, 8:10, 12:23))
> testFun(Y ~ (X1+X2+X3+Region)^2, c(1:7,10:12,14:19))
> testFun(Y ~ (X1+X2+X3+Region)^3, c(1:19, 21:29))
> testFun(Y ~ (X1+X2+X3+Region)^4, 1:32)
> 
> ## Test subsampling algorithm
> m_s_subsample <- function(x1, x2, y, control, orthogonalize=TRUE) {
+     x1 <- as.matrix(x1)
+     x2 <- as.matrix(x2)
+     y <- y
+     storage.mode(x1) <- "double"
+     storage.mode(x2) <- "double"
+     storage.mode(y) <- "double"
+     
+     z <- .C(robustbase:::R_lmrob_M_S,
+             X1=x1,
+             X2=x2,
+             y=y,
+             n=length(y),
+             p1=ncol(x1),
+             p2=ncol(x2),
+             nResample=as.integer(control$nResample),
+             scale=double(1),
+             b1=double(ncol(x1)),
+             b2=double(ncol(x2)),
+             tuning_chi=as.double(control$tuning.chi),
+             ipsi=as.integer(lmrob.psi2ipsi(control$psi)),
+             bb=as.double(control$bb),
+             K_m_s=as.integer(control$k.m_s),
+             max_k=as.integer(control$max.k),
+             rel_tol=as.double(control$rel.tol),
+             converged=logical(1),
+             trace_lev=as.integer(control$trace.lev),
+             do_descent=FALSE,
+             orthogonalize=as.logical(orthogonalize))
+     z[c("b1", "b2", "scale")]
+ }
> 
> control <- lmrob.control()
> obj <- lm(Y ~ Region + X1 + X2 + X3, education)
> splt <- lmrob.split(obj$model)
> y <- education$Y
> 
> ## test orthogonalizing
> x1 <- splt$x1
> x2 <- splt$x2
> tmp <- lmrob.lar(x1, y, control$rel.tol)
> y.tilde <- tmp$resid
> t1 <- tmp$coef
> x2.tilde <- x2
> T2 <- matrix(0, nrow=ncol(x1), ncol=ncol(x2))
> for (i in 1:ncol(x2)) {
+     tmp <- lmrob.lar(x1, x2[,i], control$rel.tol)
+     x2.tilde[,i] <- tmp$resid
+     T2[,i] <- tmp$coef
+ }
> set.seed(10)
> res1 <- m_s_subsample(x1, x2.tilde, y.tilde, control, FALSE)
> res1 <- within(res1, b1 <- drop(t1 + b1 - T2 %*% b2))
> set.seed(10)
> res2 <- m_s_subsample(x1, x2, y, control, TRUE)
> stopifnot(all.equal(res1, res2))
> 
> res <- list()
> set.seed(0)
> for (i in 1:100) {
+     tmp <- m_s_subsample(x1, x2.tilde, y.tilde, control, FALSE)
+     res[[i]] <- unlist(within(tmp, b1 <- drop(t1 + b1 - T2 %*% b2)))
+ }
> res <- do.call(rbind, res)
> ## show a summary of the results
> summary(res)
      b11               b12              b13               b14       
 Min.   :-318.21   Min.   :-32.84   Min.   :-19.386   Min.   :19.97  
 1st Qu.:-220.48   1st Qu.:-23.36   1st Qu.: -8.376   1st Qu.:30.22  
 Median :-165.13   Median :-21.37   Median : -7.415   Median :32.64  
 Mean   :-160.86   Mean   :-21.20   Mean   : -7.436   Mean   :32.86  
 3rd Qu.: -98.35   3rd Qu.:-18.33   3rd Qu.: -6.331   3rd Qu.:36.26  
 Max.   : -33.62   Max.   :-12.23   Max.   :  1.154   Max.   :42.25  
      b21                b22               b23             scale      
 Min.   :-0.03808   Min.   :0.03168   Min.   :0.2953   Min.   :29.79  
 1st Qu.: 0.01643   1st Qu.:0.03996   1st Qu.:0.4928   1st Qu.:30.37  
 Median : 0.02947   Median :0.04682   Median :0.6270   Median :30.82  
 Mean   : 0.02987   Mean   :0.04567   Mean   :0.6217   Mean   :30.84  
 3rd Qu.: 0.04804   3rd Qu.:0.05110   3rd Qu.:0.7847   3rd Qu.:31.33  
 Max.   : 0.09728   Max.   :0.06792   Max.   :0.9480   Max.   :32.12  
> ## compare with fast S solution
> obj <- lmrob(Y ~ Region + X1 + X2 + X3, education, init="S")
> coef(obj)
  (Intercept)       Region2       Region3       Region4            X1 
-135.72600303  -20.64572279   -9.84882085   24.58011727    0.03405595 
           X2            X3 
   0.04327562    0.57895757 
> obj$scale
[1] 26.40388
> 
